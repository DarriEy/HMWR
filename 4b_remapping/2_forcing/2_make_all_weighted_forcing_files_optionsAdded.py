import os
import easymore
from pathlib import Path
from shutil import copyfile
from datetime import datetime
import sys
sys.path.append(str(Path(__file__).resolve().parent.parent.parent))
from utils.control_file_utils import read_from_control, make_default_path

# --- Control file handling
controlFolder = Path('../../0_control_files')
controlFile = 'control_active.txt'

# --- Get forcing dataset
forcing_dataset = read_from_control(controlFolder/controlFile, 'forcing_dataset').lower()

# --- Set dataset-specific parameters
if forcing_dataset == 'era5':
    forcing_shape_name_key = 'forcing_shape_name'
    lat_name = 'latitude'
    lon_name = 'longitude'
elif forcing_dataset == 'rdrs':
    forcing_shape_name_key = 'forcing_rdrs_shape_name'
    lat_name = 'lat'
    lon_name = 'lon'
elif forcing_dataset == 'carra':
    forcing_shape_name_key = 'forcing_carra_shape_name'
    lat_name = 'latitude'
    lon_name = 'longitude'
else:
    raise ValueError(f"Unsupported forcing dataset: {forcing_dataset}")

# --- Find where the EASYMORE restart file is
intersect_path = read_from_control(controlFolder/controlFile, 'intersect_forcing_path')
intersect_path = Path(intersect_path) if intersect_path != 'default' else make_default_path(controlFolder, controlFile, 'shapefiles/catchment_intersection/with_forcing')

domain = read_from_control(controlFolder/controlFile, 'domain_name')
remap_file = f"{domain}_{forcing_dataset}_remapping.csv"

# --- Find the forcing files
forcing_merged_path = read_from_control(controlFolder/controlFile, 'forcing_merged_path')
forcing_merged_path = Path(forcing_merged_path) if forcing_merged_path != 'default' else make_default_path(controlFolder, controlFile, 'forcing/2_merged_data')

if forcing_dataset == 'carra':
    forcing_files = [forcing_merged_path/file for file in os.listdir(forcing_merged_path) if file.startswith('CARRA_processed_carra_iceland_') and file.endswith('.nc')]
elif forcing_dataset == 'rdrs':
    forcing_files = [forcing_merged_path/file for file in os.listdir(forcing_merged_path) if file.startswith('RDRS_monthly_') and file.endswith('.nc')]
else:
    forcing_files = [forcing_merged_path/file for file in os.listdir(forcing_merged_path) if file.endswith('.nc')]
forcing_files.sort()

# --- Find where the area-weighted forcing needs to go
forcing_basin_path = read_from_control(controlFolder/controlFile, 'forcing_basin_avg_path')
forcing_basin_path = Path(forcing_basin_path) if forcing_basin_path != 'default' else make_default_path(controlFolder, controlFile, 'forcing/3_basin_averaged_data')
forcing_basin_path.mkdir(parents=True, exist_ok=True)

# --- EASYMORE
esmr = easymore.easymore()
esmr.author_name = 'SUMMA public workflow scripts'
esmr.license = 'Copernicus data use license: https://cds.climate.copernicus.eu/api/v2/terms/static/licence-to-use-copernicus-products.pdf'
esmr.case_name = f"{read_from_control(controlFolder/controlFile, 'domain_name')}_{forcing_dataset}"

esmr.var_names = ['airpres', 'LWRadAtm', 'SWRadAtm', 'pptrate', 'airtemp', 'spechum', 'windspd', 'geopotential']
esmr.var_lat = lat_name
esmr.var_lon = lon_name
esmr.var_time = 'time'

esmr.temp_dir = ''
esmr.output_dir = str(forcing_basin_path) + '/'

esmr.remapped_dim_id = 'hru'
esmr.remapped_var_id = 'hruId'
esmr.format_list = ['f4']
esmr.fill_value_list = ['-9999']

esmr.save_csv = False
esmr.remap_csv = str(intersect_path / remap_file)
esmr.sort_ID = False
esmr.overwrite_existing_remap = False

# --- Run EASYMORE - this can be parallelized for speed ups
for file in forcing_files[1:]:  # skip the first one, as we completed that in the previous script
    esmr.source_nc = str(file)
    esmr.nc_remapper()

# --- Code provenance
def create_log(path, suffix, script_name):
    log_folder = path / '_workflow_log'
    log_folder.mkdir(parents=True, exist_ok=True)
    copyfile(script_name, log_folder / script_name)
    
    now = datetime.now()
    log_file = now.strftime('%Y%m%d') + suffix
    with open(log_folder / log_file, 'w') as file:
        lines = [
            f"Log generated by {script_name} on {now.strftime('%Y/%m/%d %H:%M:%S')}\n",
            f"Made all remaining weighted {forcing_dataset.upper()} forcing files based on restart file from intersected shapefiles of catchment and {forcing_dataset.upper()}."
        ]
        file.writelines(line + '\n' for line in lines)

create_log(forcing_basin_path, '_create_all_weighted_forcing_file_log.txt', '2_make_all_weighted_forcing_files.py')

print(f"Completed processing of all {forcing_dataset.upper()} forcing files.")